#!/usr/bin/env python3
"""
Minimal script to load and inspect the ultrafeedback-sycophantic dataset.
"""
#%%
from datasets import load_dataset
import json


print("Loading ultrafeedback-sycophantic dataset...")

# Load the dataset
syc_dataset = load_dataset("jbreuch/ultrafeedback-sycophantic")
base_dataset = load_dataset("openbmb/UltraFeedback")

# %%
len(syc_dataset['train'])


# %%
base_dataset['train'][0]['instruction']
# %%

#%%
### Let's see if the sycophantic dataset is a subset of the base dataset
syc_dataset['train'][0]['prompt']


# %%
# find that prompt in the 'instruction' part of the base dataset
for i in range(len(base_dataset['train'])):
    if base_dataset['train'][i]['instruction'] == syc_dataset['train'][0]['prompt']:
        print (f"Found at index {i}")
        print(base_dataset['train'][i]['instruction'])
        print(base_dataset['train'][i]['completions'])
        print(syc_dataset['train'][0]['chosen'])
        print(syc_dataset['train'][0]['rejected'])
        break
# %%

# are all the prompts in the sycophantic dataset unique?
prompts = [row['prompt'] for row in syc_dataset['train']]
print(len(prompts))
print(len(set(prompts)))
# no they're not, but almost!


# %%
# check if the sycophnatic prompts are a subset of the base dataset
base_prompts = [row['instruction'] for row in base_dataset['train']]
syc_len = len(syc_dataset['train'])
for i in range(len(syc_dataset['train'])):
    # print every 1000th prompt
    if i % 1000 == 0:
        print(f"Checking prompt {i} of {syc_len}")
    if syc_dataset['train'][i]['prompt'] not in base_prompts:
        print(syc_dataset['train'][i]['prompt'])
        print(f"Prompt {i} not found in base dataset")
        break

# answer: yes, they are!

#%%
base_dataset['train'][0]
# %%

# hypothesis: the sycophantic responses are all generated by gpt-4. Let's check!
# 1. extract all of the gpt-4 responses and prompts from the base dataset
data = []
for idx, i in enumerate(base_dataset['train']):
    # print every 1000th prompt
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(base_dataset['train'])}")
    if 'gpt-4' in i['models']:
        # find the index of the gpt-4 response
        gpt_idx = i['models'].index('gpt-4')
        data.append({'prompt': i['instruction'], 'completion': i['completions'][gpt_idx]['response']})

# %%
len(data)
data[0]
# %%
# check how many of the gpt-4 responses are in the sycophantic dataset
syc_prompts = [row['prompt'] for row in syc_dataset['train']]
syc_completions = [row['chosen'] for row in syc_dataset['train']]

# check how many of the gpt-4 responses are in the sycophantic dataset
num = 0
for idx, i in enumerate(data):
    # print every 1000th prompt
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(data)}")
    if i['completion'] in syc_completions:
        print(i['prompt'])
        print(f"Prompt found in sycophantic dataset")
        num += 1

print(f"Number of gpt-4 responses in sycophantic dataset: {num}")

# none of the gpt-4 responses are in the sycophantic dataset!

# %%
# ok, let's go through each of the models and see how many responses there are of them in the sycophantic dataset:
models = ['bard', 'ultralm-13b',"alpaca-7b","pythia-12b","starchat","vicuna-33b", "gpt-4",
"llama-2-13b-chat",
"starchat",
"ultralm-65b","mpt-30b-chat",
"ultralm-13b",
"vicuna-33b",
"wizardlm-7b","alpaca-7b",
"mpt-30b-chat",
"vicuna-33b",
"wizardlm-13b","pythia-12b",
"llama-2-13b-chat",
"ultralm-13b",
"wizardlm-7b","bard",
"falcon-40b-instruct",
"llama-2-70b-chat",
"wizardlm-13b",
"llama-2-13b-chat",
"llama-2-7b-chat",
"mpt-30b-chat",
"wizardlm-7b"
]
models = list(set(models))

# %%
# iterate over all the prompts in the sycophantic dataset:
for idx, i in enumerate(syc_dataset['train']):
    # print every 1000th prompt
    rejected = i['rejected']
    chosen = i['chosen']
    prompt = i['prompt']

    # check if the chosen response is in the sycophantic dataset
    if chosen in syc_completions:
        print(f"Chosen response found in sycophantic dataset")
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(syc_dataset['train'])}")
    for model in models:
        if model in i['models']:
            num += 1
    print(f"Number of {model} responses in sycophantic dataset: {num}")

#%%

#%%
# make a dict from the base dataset with they key being each of the completions and the value being the model that generated it
base_dict = {}
for i in base_dataset['train']:
    # print every 1000th prompt
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(base_dataset['train'])}")
    for idx, completion in enumerate(i['completions']):
        base_dict[completion['response']] = i['models'][idx]
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(base_dataset['train'])}")

#%%
len(base_dict)
#%%
models = list(set(base_dict.values()))
models
# %%
# make a dict with all of the models as keys
reject_dict = {}
chosen_dict = {}
for model in models:
    reject_dict[model] = 0
    chosen_dict[model] = 0


# iterate over all the reject and accept prompts in the sycophancy dataset
for idx, i in enumerate(syc_dataset['train']):
    # print every 1000th prompt
    if idx % 1000 == 0:
        print(f"Checking prompt {idx} of {len(syc_dataset['train'])}")
    reject = i['rejected'][1]['content']
    accept = i['chosen'][1]['content']
    
    prompt = i['prompt']
    #accept_model = base_dict[accept]
    reject_model = base_dict[reject]

    # for both reject and accept 
    #chosen_dict[accept_model] += 1
    reject_dict[reject_model] += 1


# %%
reject_dict
# %%
# conclusion, both of the datasets are mixes of multiple model completions, and I think that's fine!
